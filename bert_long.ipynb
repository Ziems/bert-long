{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ArmandDS/bert_for_long_text/blob/master/final_bert_long_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ojSZ5hvYnvV"
   },
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "SlW7YHjGz0o5",
    "outputId": "1120051f-c792-4568-ac1f-f469bf4e4044"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "from keras import Sequential\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import LSTM, Dense, Masking\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Dense, Input, concatenate, Layer, Lambda, Dropout, Activation\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback, TensorBoard\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3JEJQ70-Ze4X"
   },
   "source": [
    "# Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "82TK3tDYzpqm",
    "outputId": "af1cc890-7712-44ed-be0d-b30a10b4b081"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n#ifndef _WIN32\\n#include &lt;wchar.h&gt;\\n#endif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>#include \"std_testcase.h\"\\n\\ntypedef struct _l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>\\n\\n#include &lt;wchar.h&gt;\\n#include &lt;list&gt;\\n#incl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#include &lt;wchar.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#include &lt;wchar.h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                               text\n",
       "0      0  \\n\\n#ifndef _WIN32\\n#include <wchar.h>\\n#endif...\n",
       "1      0  #include \"std_testcase.h\"\\n\\ntypedef struct _l...\n",
       "2     18  \\n\\n#include <wchar.h>\\n#include <list>\\n#incl...\n",
       "3    123  #include \"std_testcase.h\"\\n\\n#include <wchar.h...\n",
       "4     16  #include \"std_testcase.h\"\\n\\n#include <wchar.h..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_csv('./data/train.csv', header=None, names=['class', 'text'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S6kyJH661det",
    "outputId": "6ab0745a-f50b-43fa-b0a8-ad44a9e6dffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102312, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Hr1v_VoZqws"
   },
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbxSBv8m6XaR"
   },
   "source": [
    "Select non null:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wmb8-t51zx0n",
    "outputId": "5156b4fd-d78f-43e2-ca3a-37c0bc20e8b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102312, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[train_raw.text.notnull()]\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "pAMdnQBv1qlC",
    "outputId": "b0cad918-406f-484e-a922-695ce9c01ab3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7effc2df6290>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw.text.apply(lambda x: len(x.split())).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "eGyH4kwB0TH6",
    "outputId": "c8117d31-a15b-49f4-d6e0-8e9b905a2c65"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>len_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102312.000000</td>\n",
       "      <td>102312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.679539</td>\n",
       "      <td>138.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.690807</td>\n",
       "      <td>95.520252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>123.000000</td>\n",
       "      <td>892.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               class        len_txt\n",
       "count  102312.000000  102312.000000\n",
       "mean       24.679539     138.020956\n",
       "std        36.690807      95.520252\n",
       "min         0.000000      23.000000\n",
       "25%         0.000000      76.000000\n",
       "50%         0.000000     109.000000\n",
       "75%        45.000000     159.000000\n",
       "max       123.000000     892.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['len_txt'] =train_raw.text.apply(lambda x: len(x.split()))\n",
    "train_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LqFgGC_TkvyA",
    "outputId": "db5dff6d-862a-45cf-a71c-957c81cb5888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102312, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SumN633drVVO"
   },
   "source": [
    "Select only the row with number of words greater than 250:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "maZQzkqv0iFa",
    "outputId": "ceb3600d-cc69-478a-d5a9-b45ce797bd61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12297, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[train_raw.len_txt >249]\n",
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WzYJ1SYn0uE6",
    "outputId": "96884ed2-2088-46d1-d026-26000441690d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n#ifndef _WIN32\\n#include &lt;wchar.h&gt;\\n#endif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  \\n\\n#ifndef _WIN32\\n#include <wchar.h>\\n#endif...      0\n",
       "1  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     26\n",
       "2  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...     44\n",
       "3  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     90\n",
       "4  #include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...     47"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = train_raw[['text', 'class']]\n",
    "train_raw.reset_index(inplace=True, drop=True)\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "beKGErd96q9p"
   },
   "source": [
    "Group similar products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "6YzGjz1o01x2",
    "outputId": "317ccd3e-52b4-4cce-da32-3841548d5e7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n#ifndef _WIN32\\n#include &lt;wchar.h&gt;\\n#endif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  \\n\\n#ifndef _WIN32\\n#include <wchar.h>\\n#endif...      0\n",
       "1  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     26\n",
       "2  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...     44\n",
       "3  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     90\n",
       "4  #include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...     47"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_raw.at[train_raw['product'] == 'Credit reporting', 'product'] = 'Credit reporting, credit repair services, or other personal consumer reports'\n",
    "# train_raw.at[train_raw['product'] == 'Credit card', 'product'] = 'Credit card or prepaid card'\n",
    "# train_raw.at[train_raw['product'] == 'Prepaid card', 'product'] = 'Credit card or prepaid card'\n",
    "# train_raw.at[train_raw['product'] == 'Payday loan', 'product'] = 'Payday loan, title loan, or personal loan'\n",
    "# train_raw.at[train_raw['product'] == 'Virtual currency', 'product'] = 'Money transfer, virtual currency, or money service'\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "4jG9xKs1CJnh",
    "outputId": "57102e86-62ab-4dc0-d4fd-f48020ecf525"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n",
      "10\n",
      "12\n",
      "17\n",
      "19\n",
      "25\n",
      "26\n",
      "35\n",
      "40\n",
      "41\n",
      "44\n",
      "45\n",
      "47\n",
      "51\n",
      "57\n",
      "58\n",
      "59\n",
      "70\n",
      "71\n",
      "73\n",
      "75\n",
      "83\n",
      "85\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "98\n",
      "100\n",
      "101\n",
      "103\n",
      "105\n",
      "108\n",
      "112\n",
      "117\n",
      "122\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "for l in np.unique(train_raw['class']):\n",
    "  print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 648
    },
    "colab_type": "code",
    "id": "ISkKV5RX344m",
    "outputId": "225b6441-e028-4983-c10d-cd2a3f45cbc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0034324890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_raw['class'].value_counts().sort_values(ascending=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "CXWBl1Ao4FW4",
    "outputId": "46ba5d89-7497-4f0a-f89c-6f25f9cc85fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n#ifndef _WIN32\\n#include &lt;wchar.h&gt;\\n#endif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  \\n\\n#ifndef _WIN32\\n#include <wchar.h>\\n#endif...      0\n",
       "1  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     26\n",
       "2  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...     44\n",
       "3  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     90\n",
       "4  #include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...     47"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw=train_raw.rename(columns = {'text':'text', 'class':'label'})\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "JFckqSM_4Pvr",
    "outputId": "46f83ccc-0d07-406c-a5d7-783c4b308412"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\n#ifndef _WIN32\\n#include &lt;wchar.h&gt;\\n#endif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  \\n\\n#ifndef _WIN32\\n#include <wchar.h>\\n#endif...      0\n",
       "1  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...      7\n",
       "2  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...     11\n",
       "3  #include \"std_testcase.h\"\\n\\n#ifdef _WIN32\\n#i...     24\n",
       "4  #include \"std_testcase.h\"\\n\\n#define MAX_LOOP ...     13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "train_raw['label'] = LE.fit_transform(train_raw['label'])\n",
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VvAEbfcK40vP",
    "outputId": "1eecd4ae-177d-4578-b3df-adb2f137451f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(train_raw['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjTcB2IElYK-"
   },
   "outputs": [],
   "source": [
    "train = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "_KSdpULo4vBM",
    "outputId": "fbd5b957-68d9-49fd-dc57-e485fa852c53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>#include &lt;map&gt;\\n\\n#ifdef _WIN32\\n#define BASEP...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>\\n\\n#ifdef _WIN32\\n#include &lt;winsock2.h&gt;\\n#inc...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>#include &lt;stdarg.h&gt;\\n#include \"std_testcase.h\"...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6621</th>\n",
       "      <td>#include \"std_testcase.h\"\\n\\n#ifndef _WIN32\\n#...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "47    #include <map>\\n\\n#ifdef _WIN32\\n#define BASEP...      2\n",
       "9330  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...     27\n",
       "9318  \\n\\n#ifdef _WIN32\\n#include <winsock2.h>\\n#inc...      7\n",
       "2594  #include <stdarg.h>\\n#include \"std_testcase.h\"...      0\n",
       "6621  #include \"std_testcase.h\"\\n\\n#ifndef _WIN32\\n#...     15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.reindex(np.random.permutation(train.index))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJaaGqEC61Tw"
   },
   "source": [
    "Clean the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFLkBvrnyKnt"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(text):\n",
    "  text = re.sub(\"'\", \"\",text)\n",
    "  text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "C4yHuGEayROw",
    "outputId": "000869c2-f3eb-46c1-8aec-cb54a868d372"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>include map ifdef _WIN32 define BASEPATH c te...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9330</th>\n",
       "      <td>ifdef _WIN32 include winsock2 h include windo...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9318</th>\n",
       "      <td>ifdef _WIN32 include winsock2 h include windo...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>include stdarg h include std_testcase h ifnde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6621</th>\n",
       "      <td>include std_testcase h ifndef _WIN32 include ...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "47     include map ifdef _WIN32 define BASEPATH c te...      2\n",
       "9330   ifdef _WIN32 include winsock2 h include windo...     27\n",
       "9318   ifdef _WIN32 include winsock2 h include windo...      7\n",
       "2594   include stdarg h include std_testcase h ifnde...      0\n",
       "6621   include std_testcase h ifndef _WIN32 include ...     15"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text']  = train.text.apply(clean_txt)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "S3EJew8g5cUK",
    "outputId": "5b0fe85f-23df-46ad-f705-776ad8e4d971"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11922</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>ifdef _WIN32 define BASEPATH L c temp else in...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10957</th>\n",
       "      <td>include std_testcase h include wchar h ifdef ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11606</th>\n",
       "      <td>include std_testcase h include wchar h includ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label\n",
       "11922   include std_testcase h ifdef _WIN32 include w...      0\n",
       "11326   ifdef _WIN32 define BASEPATH L c temp else in...      2\n",
       "10957   include std_testcase h include wchar h ifdef ...     36\n",
       "11606   include std_testcase h include wchar h includ...      0\n",
       "8579    include std_testcase h ifdef _WIN32 include w...      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=35)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "2Cr7Ch3_5rnH",
    "outputId": "288d77ec-56c6-4fb5-b780-4216cf1c9f9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifdef _WIN32 define BASEPATH L c temp else in...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   include std_testcase h ifdef _WIN32 include w...      0\n",
       "1   ifdef _WIN32 define BASEPATH L c temp else in...      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "6-1O5J9G54hV",
    "outputId": "dcc34ce3-2aa4-4c2b-eb27-d23bf4196f6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include wchar h ifdef _WIN32 define FULL_COMM...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifdef _WIN32 include winsock2 h include windo...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0   include wchar h ifdef _WIN32 define FULL_COMM...      0\n",
       "1   ifdef _WIN32 include winsock2 h include windo...      7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.reset_index(drop=True, inplace=True)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ziIsgHqrz0n6",
    "outputId": "7020b652-4989-41b1-9e32-c83666c6f9ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2460, 2), (9837, 2))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "TGq2lzLG59SC",
    "outputId": "776bf6cb-74ba-40eb-c26a-247b684b574a"
   },
   "outputs": [],
   "source": [
    "#Installing BERT module\n",
    "# !pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "zTcMyKKl6DdA",
    "outputId": "fc31a0bb-4c45-4b7c-8dc9-752261c06f51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing BERT modules\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ej8QOozZbEva"
   },
   "source": [
    "# Setting The Output Directory for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NNPhIMrr6ra9",
    "outputId": "ffc63c79-3bea-481d-8263-55f3e65decdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Model output directory: ./bert_code_category *****\n"
     ]
    }
   ],
   "source": [
    "# Set the output directory for saving model file\n",
    "OUTPUT_DIR = './bert_code_category'\n",
    "\n",
    "# #@markdown Whether or not to clear/delete the directory and create a new one\n",
    "# DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "# if DO_DELETE:\n",
    "#   try:\n",
    "#     tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "#   except:\n",
    "#     pass\n",
    "\n",
    "# tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0YGONt0p60Ay",
    "outputId": "5b986fab-16ed-4613-d2c9-554765ed86bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape : (9837, 2)\n",
      "Validation Set Shape : (2460, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Shape :\", train.shape)\n",
    "print(\"Validation Set Shape :\", val.shape)\n",
    "# print(\"Test Set Shape :\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s6NYKx4P7N66",
    "outputId": "e7d7aa06-98d7-4d6f-d164-93b721c872e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "# The list containing all the classes (train['SECTION'].unique())\n",
    "label_list = [x for x in np.unique(train.label)]\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oOSEd24bbiUq"
   },
   "source": [
    "# Splitting the Data into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ausf5AlOkPCH"
   },
   "outputs": [],
   "source": [
    "def get_split(text1):\n",
    "  l_total = []\n",
    "  l_parcial = []\n",
    "  if len(text1.split())//150 >0:\n",
    "    n = len(text1.split())//150\n",
    "  else: \n",
    "    n = 1\n",
    "  for w in range(n):\n",
    "    if w == 0:\n",
    "      l_parcial = text1.split()[:200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "    else:\n",
    "      l_parcial = text1.split()[w*150:w*150 + 200]\n",
    "      l_total.append(\" \".join(l_parcial))\n",
    "  return l_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "E-u6mDkbLpTY",
    "outputId": "972100f3-569c-4a27-a24c-3fb2728d3581"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[include std_testcase h ifdef _WIN32 include w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifdef _WIN32 define BASEPATH L c temp else in...</td>\n",
       "      <td>2</td>\n",
       "      <td>[ifdef _WIN32 define BASEPATH L c temp else in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>include std_testcase h include wchar h ifdef ...</td>\n",
       "      <td>36</td>\n",
       "      <td>[include std_testcase h include wchar h ifdef ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>include std_testcase h include wchar h includ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[include std_testcase h include wchar h includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[include std_testcase h ifdef _WIN32 include w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0   include std_testcase h ifdef _WIN32 include w...      0   \n",
       "1   ifdef _WIN32 define BASEPATH L c temp else in...      2   \n",
       "2   include std_testcase h include wchar h ifdef ...     36   \n",
       "3   include std_testcase h include wchar h includ...      0   \n",
       "4   include std_testcase h ifdef _WIN32 include w...      0   \n",
       "\n",
       "                                          text_split  \n",
       "0  [include std_testcase h ifdef _WIN32 include w...  \n",
       "1  [ifdef _WIN32 define BASEPATH L c temp else in...  \n",
       "2  [include std_testcase h include wchar h ifdef ...  \n",
       "3  [include std_testcase h include wchar h includ...  \n",
       "4  [include std_testcase h ifdef _WIN32 include w...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text_split'] = train[DATA_COLUMN].apply(get_split)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "-zrlehCFUplB",
    "outputId": "7bd7c47a-adae-418a-c50e-29b2deb3c7d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include wchar h ifdef _WIN32 define FULL_COMM...</td>\n",
       "      <td>0</td>\n",
       "      <td>[include wchar h ifdef _WIN32 define FULL_COMM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifdef _WIN32 include winsock2 h include windo...</td>\n",
       "      <td>7</td>\n",
       "      <td>[ifdef _WIN32 include winsock2 h include windo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0   include wchar h ifdef _WIN32 define FULL_COMM...      0   \n",
       "1   ifdef _WIN32 include winsock2 h include windo...      7   \n",
       "\n",
       "                                          text_split  \n",
       "0  [include wchar h ifdef _WIN32 define FULL_COMM...  \n",
       "1  [ifdef _WIN32 include winsock2 h include windo...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['text_split'] = val[DATA_COLUMN].apply(get_split)\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5_zMerj1VGaM",
    "outputId": "cc839f6a-8be6-40a9-aaa9-29752d8d5fff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16103, 16103, 16103)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l = []\n",
    "label_l = []\n",
    "index_l =[]\n",
    "for idx,row in train.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    train_l.append(l)\n",
    "    label_l.append(row['label'])\n",
    "    index_l.append(idx)\n",
    "len(train_l), len(label_l), len(index_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rBrXEaxHVNG4",
    "outputId": "de4dbc34-1fde-4233-a902-ab522cfc9520"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4000, 4000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_l = []\n",
    "val_label_l = []\n",
    "val_index_l = []\n",
    "for idx,row in val.iterrows():\n",
    "  for l in row['text_split']:\n",
    "    val_l.append(l)\n",
    "    val_label_l.append(row['label'])\n",
    "    val_index_l.append(idx)\n",
    "len(val_l), len(val_label_l), len(val_index_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hu5Sx8Rm0bAj"
   },
   "source": [
    "The final dataset for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mojRk8kWVVB4",
    "outputId": "95c4ea0f-7800-47b0-fa8a-9005671da2a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include std_testcase h ifdef _WIN32 include wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ifdef _WIN32 define BASEPATH L c temp else inc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>getenv endif ifdef _WIN32 define OPEN _wopen d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>include std_testcase h include wchar h ifdef _...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>include std_testcase h include wchar h include...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  include std_testcase h ifdef _WIN32 include wi...      0\n",
       "1  ifdef _WIN32 define BASEPATH L c temp else inc...      2\n",
       "2  getenv endif ifdef _WIN32 define OPEN _wopen d...      2\n",
       "3  include std_testcase h include wchar h ifdef _...     36\n",
       "4  include std_testcase h include wchar h include...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({DATA_COLUMN:train_l, LABEL_COLUMN:label_l})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "k_I-ZbSKVmrZ",
    "outputId": "ab55b3b8-5524-4cb3-bb23-a0a10c3a2bf0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include wchar h ifdef _WIN32 define FULL_COMMA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h define INVALID_SOCKET 1 define SOCKET_ERROR ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ifdef _WIN32 include winsock2 h include window...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>include wchar h ifdef _WIN32 include winsock2 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TCP_PORT 27015 define LISTEN_BACKLOG 5 define ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  include wchar h ifdef _WIN32 define FULL_COMMA...      0\n",
       "1  h define INVALID_SOCKET 1 define SOCKET_ERROR ...      0\n",
       "2  ifdef _WIN32 include winsock2 h include window...      7\n",
       "3  include wchar h ifdef _WIN32 include winsock2 ...      0\n",
       "4  TCP_PORT 27015 define LISTEN_BACKLOG 5 define ...      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.DataFrame({DATA_COLUMN:val_l, LABEL_COLUMN:val_label_l})\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "og08g7DScPtK"
   },
   "source": [
    "# BERT: Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PWVomvm7TV5"
   },
   "source": [
    "Process the data for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-_zLSnh7evE"
   },
   "outputs": [],
   "source": [
    "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "UOq7ETNe7zGJ",
    "outputId": "0c86519a-5376-4b21-be65-9c12f99afb6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <bert.run_classifier.InputExample object at 0x...\n",
       "1        <bert.run_classifier.InputExample object at 0x...\n",
       "2        <bert.run_classifier.InputExample object at 0x...\n",
       "3        <bert.run_classifier.InputExample object at 0x...\n",
       "4        <bert.run_classifier.InputExample object at 0x...\n",
       "                               ...                        \n",
       "16098    <bert.run_classifier.InputExample object at 0x...\n",
       "16099    <bert.run_classifier.InputExample object at 0x...\n",
       "16100    <bert.run_classifier.InputExample object at 0x...\n",
       "16101    <bert.run_classifier.InputExample object at 0x...\n",
       "16102    <bert.run_classifier.InputExample object at 0x...\n",
       "Length: 16103, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "d0E8U0OQ8VW6",
    "outputId": "0934f3f9-f7ae-44dc-fbef-4e038c8bb99a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 - guid of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - text_a of training set :  include std_testcase h ifdef _WIN32 include winsock2 h include windows h include direct h pragma comment lib ws2_32 define CLOSE_SOCKET closesocket else include sys types h include sys socket h include netinet in h include arpa inet h include unistd h define INVALID_SOCKET 1 define SOCKET_ERROR 1 define CLOSE_SOCKET close define SOCKET int endif define TCP_PORT 27015 define IP_ADDRESS 127 0 0 1 define CHAR_ARRAY_SIZE 3 sizeof data 2 static void func3 int data int result data 1 printIntLine result static void func4 int data void funcPtr int func3 data 0 data 2 funcPtr data static void func5 int data if data INT_MIN int result data 1 printIntLine result else printLine data value is too large to perform subtraction static void func6 int data void funcPtr int func5 data 0 ifdef _WIN32 WSADATA wsaData int wsaDataInit 0 endif int recvResult struct sockaddr_in service SOCKET connectSocket INVALID_SOCKET char inputBuffer CHAR_ARRAY_SIZE do ifdef _WIN32 if WSAStartup MAKEWORD 2 2 wsaData NO_ERROR break wsaDataInit 1 endif connectSocket socket AF_INET SOCK_STREAM IPPROTO_TCP if connectSocket INVALID_SOCKET break memset service 0 sizeof service service sin_family AF_INET service sin_addr s_addr inet_addr IP_ADDRESS service sin_port htons TCP_PORT if connect connectSocket struct sockaddr service sizeof service SOCKET_ERROR break recvResult\n",
      "\n",
      "__________\n",
      "Row 0 - text_b of training set :  None\n",
      "\n",
      "__________\n",
      "Row 0 - label of training set :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoIt5AHadACM"
   },
   "source": [
    "# BERT: Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "W4PZ8ogj8ae2",
    "outputId": "26a10fed-e770-41a2-e716-11d5cc7dc2ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qS_ybJmv8lye",
    "outputId": "2c48b73b-eacc-4073-defc-934eaf83a24f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30522"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "O6OqoZjv8r27",
    "outputId": "bad53d19-4e97-47cb-ad7c-3781ebb5e303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['include', 'st', '##d', '_', 'test', '##case', 'h', 'if', '##de', '##f', '_', 'win', '##32', 'include', 'wins', '##ock', '##2', 'h', 'include', 'windows', 'h', 'include', 'direct', 'h', 'pr', '##ag', '##ma', 'comment', 'li', '##b', 'w', '##s', '##2', '_', '32', 'define', 'close', '_', 'socket', 'closes', '##ock', '##et', 'else', 'include', 'sy', '##s', 'types', 'h', 'include', 'sy', '##s', 'socket', 'h', 'include', 'net', '##ine', '##t', 'in', 'h', 'include', 'ar', '##pa', 'in', '##et', 'h', 'include', 'un', '##ist', '##d', 'h', 'define', 'invalid', '_', 'socket', '1', 'define', 'socket', '_', 'error', '1', 'define', 'close', '_', 'socket', 'close', 'define', 'socket', 'int', 'end', '##if', 'define', 'tc', '##p', '_', 'port', '270', '##15', 'define', 'ip', '_', 'address', '127', '0', '0', '1', 'define', 'char', '_', 'array', '_', 'size', '3', 'size', '##of', 'data', '2', 'static', 'void', 'fun', '##c', '##3', 'int', 'data', 'int', 'result', 'data', '1', 'print', '##int', '##line', 'result', 'static', 'void', 'fun', '##c', '##4', 'int', 'data', 'void', 'fun', '##cp', '##tr', 'int', 'fun', '##c', '##3', 'data', '0', 'data', '2', 'fun', '##cp', '##tr', 'data', 'static', 'void', 'fun', '##c', '##5', 'int', 'data', 'if', 'data', 'int', '_', 'min', 'int', 'result', 'data', '1', 'print', '##int', '##line', 'result', 'else', 'print', '##line', 'data', 'value', 'is', 'too', 'large', 'to', 'perform', 'sub', '##tra', '##ction', 'static', 'void', 'fun', '##c', '##6', 'int', 'data', 'void', 'fun', '##cp', '##tr', 'int', 'fun', '##c', '##5', 'data', '0', 'if', '##de', '##f', '_', 'win', '##32', 'w', '##sa', '##da', '##ta', 'w', '##sa', '##da', '##ta', 'int', 'w', '##sa', '##da', '##tain', '##it', '0', 'end', '##if', 'int', 'rec', '##vres', '##ult', 'st', '##ru', '##ct', 'sock', '##ad', '##dr', '_', 'in', 'service', 'socket', 'connects', '##ock', '##et', 'invalid', '_', 'socket', 'char', 'input', '##bu', '##ffer', 'char', '_', 'array', '_', 'size', 'do', 'if', '##de', '##f', '_', 'win', '##32', 'if', 'w', '##sas', '##tar', '##tu', '##p', 'make', '##word', '2', '2', 'w', '##sa', '##da', '##ta', 'no', '_', 'error', 'break', 'w', '##sa', '##da', '##tain', '##it', '1', 'end', '##if', 'connects', '##ock', '##et', 'socket', 'af', '_', 'in', '##et', 'sock', '_', 'stream', 'ip', '##pro', '##to', '_', 'tc', '##p', 'if', 'connects', '##ock', '##et', 'invalid', '_', 'socket', 'break', 'me', '##ms', '##et', 'service', '0', 'size', '##of', 'service', 'service', 'sin', '_', 'family', 'af', '_', 'in', '##et', 'service', 'sin', '_', 'add', '##r', 's', '_', 'add', '##r', 'in', '##et', '_', 'add', '##r', 'ip', '_', 'address', 'service', 'sin', '_', 'port', 'h', '##ton', '##s', 'tc', '##p', '_', 'port', 'if', 'connect', 'connects', '##ock', '##et', 'st', '##ru', '##ct', 'sock', '##ad', '##dr', 'service', 'size', '##of', 'service', 'socket', '_', 'error', 'break', 'rec', '##vres', '##ult']\n"
     ]
    }
   ],
   "source": [
    "#Here is what the tokenised sample of the first training set observation looks like\n",
    "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q87k_orF8vpz"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G_LBy-yy-GSU",
    "outputId": "a1c02dff-0cd3-4ef8-c013-ced8dd6b484f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 16103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 16103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define ip _ address 127 0 0 1 define char _ array _ size 3 size ##of data 2 static void fun ##c ##3 int data int result data 1 print ##int ##line result static void fun ##c ##4 int data void fun ##cp ##tr int fun ##c ##3 data 0 data 2 fun ##cp ##tr data static void fun ##c ##5 int data if data int _ min int result data 1 print ##int ##line result else print ##line data value is too large to perform sub ##tra ##ction static void fun ##c ##6 int data void fun ##cp ##tr [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define ip _ address 127 0 0 1 define char _ array _ size 3 size ##of data 2 static void fun ##c ##3 int data int result data 1 print ##int ##line result static void fun ##c ##4 int data void fun ##cp ##tr int fun ##c ##3 data 0 data 2 fun ##cp ##tr data static void fun ##c ##5 int data if data int _ min int result data 1 print ##int ##line result else print ##line data value is too large to perform sub ##tra ##ction static void fun ##c ##6 int data void fun ##cp ##tr [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 12997 1035 4769 13029 1014 1014 1015 9375 25869 1035 9140 1035 2946 1017 2946 11253 2951 1016 10763 11675 4569 2278 2509 20014 2951 20014 2765 2951 1015 6140 18447 4179 2765 10763 11675 4569 2278 2549 20014 2951 11675 4569 21906 16344 20014 4569 2278 2509 2951 1014 2951 1016 4569 21906 16344 2951 10763 11675 4569 2278 2629 20014 2951 2065 2951 20014 1035 8117 20014 2765 2951 1015 6140 18447 4179 2765 2842 6140 4179 2951 3643 2003 2205 2312 2000 4685 4942 6494 7542 10763 11675 4569 2278 2575 20014 2951 11675 4569 21906 16344 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 12997 1035 4769 13029 1014 1014 1015 9375 25869 1035 9140 1035 2946 1017 2946 11253 2951 1016 10763 11675 4569 2278 2509 20014 2951 20014 2765 2951 1015 6140 18447 4179 2765 10763 11675 4569 2278 2549 20014 2951 11675 4569 21906 16344 20014 4569 2278 2509 2951 1014 2951 1016 4569 21906 16344 2951 10763 11675 4569 2278 2629 20014 2951 2065 2951 20014 1035 8117 20014 2765 2951 1015 6140 18447 4179 2765 2842 6140 4179 2951 3643 2003 2205 2312 2000 4685 4942 6494 7542 10763 11675 4569 2278 2575 20014 2951 11675 4569 21906 16344 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##3 wc ##har _ t data void fun ##c ##1 wc ##har _ t data fun ##c ##3 data if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##3 wc ##har _ t data void fun ##c ##1 wc ##har _ t data fun ##c ##3 data if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2509 15868 8167 1035 1056 2951 11675 4569 2278 2487 15868 8167 1035 1056 2951 4569 2278 2509 2951 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2509 15868 8167 1035 1056 2951 11675 4569 2278 2487 15868 8167 1035 1056 2951 4569 2278 2509 2951 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##7 wc ##har _ t data void fun ##c ##5 wc ##har _ t data fun ##c ##7 data if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##7 wc ##har _ t data int filed ##es ##c filed ##es ##c open data o _ rd ##wr o _ cr ##ea ##t s _ ir ##ead s _ i ##write if filed ##es ##c 1 close filed ##es ##c if [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##7 wc ##har _ t data void fun ##c ##5 wc ##har _ t data fun ##c ##7 data if ##de ##f _ win ##32 define base ##path l c te ##mp else include wc ##har h define base ##path l t ##mp end ##if define en ##v _ variable l add if ##de ##f _ win ##32 define get ##en ##v _ w ##get ##en ##v else define get ##en ##v get ##en ##v end ##if if ##de ##f _ win ##32 define open _ wo ##pen define close _ close else include un ##ist ##d h define open open define close close end ##if names ##pace gen ##ns ##1 void fun ##c ##7 wc ##har _ t data int filed ##es ##c filed ##es ##c open data o _ rd ##wr o _ cr ##ea ##t s _ ir ##ead s _ i ##write if filed ##es ##c 1 close filed ##es ##c if [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2581 15868 8167 1035 1056 2951 11675 4569 2278 2629 15868 8167 1035 1056 2951 4569 2278 2581 2951 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2581 15868 8167 1035 1056 2951 20014 6406 2229 2278 6406 2229 2278 2330 2951 1051 1035 16428 13088 1051 1035 13675 5243 2102 1055 1035 20868 13775 1055 1035 1045 26373 2065 6406 2229 2278 1015 2485 6406 2229 2278 2065 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2581 15868 8167 1035 1056 2951 11675 4569 2278 2629 15868 8167 1035 1056 2951 4569 2278 2581 2951 2065 3207 2546 1035 2663 16703 9375 2918 15069 1048 1039 8915 8737 2842 2421 15868 8167 1044 9375 2918 15069 1048 1056 8737 2203 10128 9375 4372 2615 1035 8023 1048 5587 2065 3207 2546 1035 2663 16703 9375 2131 2368 2615 1035 1059 18150 2368 2615 2842 9375 2131 2368 2615 2131 2368 2615 2203 10128 2065 3207 2546 1035 2663 16703 9375 2330 1035 24185 11837 9375 2485 1035 2485 2842 2421 4895 2923 2094 1044 9375 2330 2330 9375 2485 2485 2203 10128 3415 15327 8991 3619 2487 11675 4569 2278 2581 15868 8167 1035 1056 2951 20014 6406 2229 2278 6406 2229 2278 2330 2951 1051 1035 16428 13088 1051 1035 13675 5243 2102 1055 1035 20868 13775 1055 1035 1045 26373 2065 6406 2229 2278 1015 2485 6406 2229 2278 2065 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 2 (id = 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define ip _ address 127 0 0 1 define search _ char l ##s void fun ##c ##1 wc ##har _ t data data wc ##har _ t mall ##oc 100 size ##of wc ##har _ t if data null exit 1 data 0 l 0 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult st ##ru ##ct sock ##ad ##dr _ in service wc ##har _ t replace socket connects ##ock ##et invalid _ socket size _ t [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define ip _ address 127 0 0 1 define search _ char l ##s void fun ##c ##1 wc ##har _ t data data wc ##har _ t mall ##oc 100 size ##of wc ##har _ t if data null exit 1 data 0 l 0 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult st ##ru ##ct sock ##ad ##dr _ in service wc ##har _ t replace socket connects ##ock ##et invalid _ socket size _ t [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 12997 1035 4769 13029 1014 1014 1015 9375 3945 1035 25869 1048 2015 11675 4569 2278 2487 15868 8167 1035 1056 2951 2951 15868 8167 1035 1056 6670 10085 2531 2946 11253 15868 8167 1035 1056 2065 2951 19701 6164 1015 2951 1014 1048 1014 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 2358 6820 6593 28407 4215 13626 1035 1999 2326 15868 8167 1035 1056 5672 22278 8539 7432 3388 19528 1035 22278 2946 1035 1056 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 12997 1035 4769 13029 1014 1014 1015 9375 3945 1035 25869 1048 2015 11675 4569 2278 2487 15868 8167 1035 1056 2951 2951 15868 8167 1035 1056 6670 10085 2531 2946 11253 15868 8167 1035 1056 2065 2951 19701 6164 1015 2951 1014 1048 1014 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 2358 6820 6593 28407 4215 13626 1035 1999 2326 15868 8167 1035 1056 5672 22278 8539 7432 3388 19528 1035 22278 2946 1035 1056 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 36 (id = 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 36 (id = 36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h include wc ##har h include list include ios ##tream using names ##pace st ##d static con ##st int static _ con ##st _ five 5 names ##pace var ##1 static void fun ##c ##2 list int data if static _ con ##st _ five 5 data push _ back 100 data push _ back 0 if static _ con ##st _ five 5 print ##line benign fixed string else list int it ##era ##tor i co ##ut the list contains for i data begin i data end i co ##ut i co ##ut end ##l static void fun ##c ##3 list int data if static _ con ##st _ five 5 data push _ back 100 data push _ back 0 if static _ con ##st _ five 5 list int it ##era ##tor i co ##ut the list contains for i data begin i data end i co ##ut i co ##ut end ##l static void fun ##c ##4 list int data if static _ con ##st _ five 5 print ##line benign fixed string else data push _ back 100 data push _ back 200 if static _ con [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include st ##d _ test ##case h include wc ##har h include list include ios ##tream using names ##pace st ##d static con ##st int static _ con ##st _ five 5 names ##pace var ##1 static void fun ##c ##2 list int data if static _ con ##st _ five 5 data push _ back 100 data push _ back 0 if static _ con ##st _ five 5 print ##line benign fixed string else list int it ##era ##tor i co ##ut the list contains for i data begin i data end i co ##ut i co ##ut end ##l static void fun ##c ##3 list int data if static _ con ##st _ five 5 data push _ back 100 data push _ back 0 if static _ con ##st _ five 5 list int it ##era ##tor i co ##ut the list contains for i data begin i data end i co ##ut i co ##ut end ##l static void fun ##c ##4 list int data if static _ con ##st _ five 5 print ##line benign fixed string else data push _ back 100 data push _ back 200 if static _ con [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2421 15868 8167 1044 2421 2862 2421 16380 25379 2478 3415 15327 2358 2094 10763 9530 3367 20014 10763 1035 9530 3367 1035 2274 1019 3415 15327 13075 2487 10763 11675 4569 2278 2475 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 2951 5245 1035 2067 2531 2951 5245 1035 2067 1014 2065 10763 1035 9530 3367 1035 2274 1019 6140 4179 28378 4964 5164 2842 2862 20014 2009 6906 4263 1045 2522 4904 1996 2862 3397 2005 1045 2951 4088 1045 2951 2203 1045 2522 4904 1045 2522 4904 2203 2140 10763 11675 4569 2278 2509 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 2951 5245 1035 2067 2531 2951 5245 1035 2067 1014 2065 10763 1035 9530 3367 1035 2274 1019 2862 20014 2009 6906 4263 1045 2522 4904 1996 2862 3397 2005 1045 2951 4088 1045 2951 2203 1045 2522 4904 1045 2522 4904 2203 2140 10763 11675 4569 2278 2549 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 6140 4179 28378 4964 5164 2842 2951 5245 1035 2067 2531 2951 5245 1035 2067 3263 2065 10763 1035 9530 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 2358 2094 1035 3231 18382 1044 2421 15868 8167 1044 2421 2862 2421 16380 25379 2478 3415 15327 2358 2094 10763 9530 3367 20014 10763 1035 9530 3367 1035 2274 1019 3415 15327 13075 2487 10763 11675 4569 2278 2475 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 2951 5245 1035 2067 2531 2951 5245 1035 2067 1014 2065 10763 1035 9530 3367 1035 2274 1019 6140 4179 28378 4964 5164 2842 2862 20014 2009 6906 4263 1045 2522 4904 1996 2862 3397 2005 1045 2951 4088 1045 2951 2203 1045 2522 4904 1045 2522 4904 2203 2140 10763 11675 4569 2278 2509 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 2951 5245 1035 2067 2531 2951 5245 1035 2067 1014 2065 10763 1035 9530 3367 1035 2274 1019 2862 20014 2009 6906 4263 1045 2522 4904 1996 2862 3397 2005 1045 2951 4088 1045 2951 2203 1045 2522 4904 1045 2522 4904 2203 2140 10763 11675 4569 2278 2549 2862 20014 2951 2065 10763 1035 9530 3367 1035 2274 1019 6140 4179 28378 4964 5164 2842 2951 5245 1035 2067 2531 2951 5245 1035 2067 3263 2065 10763 1035 9530 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 16103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 10000 of 16103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include un ##ist ##d h define full _ command l l ##s end ##if if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 if ##de ##f _ win ##32 define pope ##n _ w ##pop ##en define pc ##los ##e _ pc ##los ##e else define pope ##n pope ##n define pc ##los ##e pc ##los ##e end ##if void fun ##c ##4 wc ##har _ t data void fun ##c ##2 wc ##har _ t data fun ##c ##4 data include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include un ##ist ##d h define full _ command l l ##s end ##if if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 if ##de ##f _ win ##32 define pope ##n _ w ##pop ##en define pc ##los ##e _ pc ##los ##e else define pope ##n pope ##n define pc ##los ##e pc ##los ##e end ##if void fun ##c ##4 wc ##har _ t data void fun ##c ##2 wc ##har _ t data fun ##c ##4 data include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 4895 2923 2094 1044 9375 2440 1035 3094 1048 1048 2015 2203 10128 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 2065 3207 2546 1035 2663 16703 9375 4831 2078 1035 1059 16340 2368 9375 7473 10483 2063 1035 7473 10483 2063 2842 9375 4831 2078 4831 2078 9375 7473 10483 2063 7473 10483 2063 2203 10128 11675 4569 2278 2549 15868 8167 1035 1056 2951 11675 4569 2278 2475 15868 8167 1035 1056 2951 4569 2278 2549 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 4895 2923 2094 1044 9375 2440 1035 3094 1048 1048 2015 2203 10128 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 2065 3207 2546 1035 2663 16703 9375 4831 2078 1035 1059 16340 2368 9375 7473 10483 2063 1035 7473 10483 2063 2842 9375 4831 2078 4831 2078 9375 7473 10483 2063 7473 10483 2063 2203 10128 11675 4569 2278 2549 15868 8167 1035 1056 2951 11675 4569 2278 2475 15868 8167 1035 1056 2951 4569 2278 2549 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 if ##de ##f _ win ##32 define pope ##n _ w ##pop ##en define pc ##los ##e _ pc ##los ##e else define pope ##n pope ##n define pc ##los ##e pc ##los ##e end ##if void fun ##c ##6 wc ##har _ t data void fun ##c ##4 wc ##har _ t data fun ##c ##6 data include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include un ##ist ##d h define full _ command l l ##s end ##if if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 if ##de ##f _ win ##32 define pope ##n _ w ##pop ##en define pc ##los ##e _ pc ##los ##e else define pope ##n pope ##n define pc ##los ##e pc ##los ##e end ##if void fun ##c ##6 wc ##har _ t data void fun ##c ##4 wc ##har _ t data fun ##c ##6 data include wc ##har h if ##de ##f _ win ##32 define full _ command l dir else include un ##ist ##d h define full _ command l l ##s end ##if if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 2065 3207 2546 1035 2663 16703 9375 4831 2078 1035 1059 16340 2368 9375 7473 10483 2063 1035 7473 10483 2063 2842 9375 4831 2078 4831 2078 9375 7473 10483 2063 7473 10483 2063 2203 10128 11675 4569 2278 2575 15868 8167 1035 1056 2951 11675 4569 2278 2549 15868 8167 1035 1056 2951 4569 2278 2575 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 4895 2923 2094 1044 9375 2440 1035 3094 1048 1048 2015 2203 10128 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 2065 3207 2546 1035 2663 16703 9375 4831 2078 1035 1059 16340 2368 9375 7473 10483 2063 1035 7473 10483 2063 2842 9375 4831 2078 4831 2078 9375 7473 10483 2063 7473 10483 2063 2203 10128 11675 4569 2278 2575 15868 8167 1035 1056 2951 11675 4569 2278 2549 15868 8167 1035 1056 2951 4569 2278 2575 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 9375 2440 1035 3094 1048 16101 2842 2421 4895 2923 2094 1044 9375 2440 1035 3094 1048 1048 2015 2203 10128 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 define char _ array _ size 8 ex ##tern int var ##1 short fun ##c ##1 short data if var ##1 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult int te ##mp ##int st ##ru ##ct sock ##ad ##dr _ in service socket listen ##so ##cke ##t invalid _ socket socket accepts ##ock ##et invalid _ socket char input ##bu ##ffer char _ array _ size do if ##de ##f _ win ##32 if w ##sas ##tar ##tu ##p make ##word 2 2 [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 define char _ array _ size 8 ex ##tern int var ##1 short fun ##c ##1 short data if var ##1 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult int te ##mp ##int st ##ru ##ct sock ##ad ##dr _ in service socket listen ##so ##cke ##t invalid _ socket socket accepts ##ock ##et invalid _ socket char input ##bu ##ffer char _ array _ size do if ##de ##f _ win ##32 if w ##sas ##tar ##tu ##p make ##word 2 2 [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 25869 1035 9140 1035 2946 1022 4654 16451 20014 13075 2487 2460 4569 2278 2487 2460 2951 2065 13075 2487 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 20014 8915 8737 18447 2358 6820 6593 28407 4215 13626 1035 1999 2326 22278 4952 6499 19869 2102 19528 1035 22278 22278 13385 7432 3388 19528 1035 22278 25869 7953 8569 12494 25869 1035 9140 1035 2946 2079 2065 3207 2546 1035 2663 16703 2065 1059 20939 7559 8525 2361 2191 18351 1016 1016 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 25869 1035 9140 1035 2946 1022 4654 16451 20014 13075 2487 2460 4569 2278 2487 2460 2951 2065 13075 2487 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 20014 8915 8737 18447 2358 6820 6593 28407 4215 13626 1035 1999 2326 22278 4952 6499 19869 2102 19528 1035 22278 22278 13385 7432 3388 19528 1035 22278 25869 7953 8569 12494 25869 1035 9140 1035 2946 2079 2065 3207 2546 1035 2663 16703 2065 1059 20939 7559 8525 2361 2191 18351 1016 1016 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 7 (id = 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 7 (id = 7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 define search _ char l ##s ex ##tern wc ##har _ t var ##1 ex ##tern wc ##har _ t var ##2 void fun ##c ##2 wc ##har _ t data var ##2 size _ t i for i 0 i wc ##sle ##n data i if data i search _ char print ##line we have a match break free data include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes ##ock ##et else include sy ##s types h include sy ##s socket h include net ##ine ##t in h include ar ##pa in ##et h include un ##ist ##d h define invalid _ socket 1 define socket _ error 1 define close _ socket close define socket int end ##if define tc ##p _ port 270 ##15 define listen _ back ##log 5 define search _ char l ##s ex ##tern wc ##har _ t var ##1 ex ##tern wc ##har _ t var ##2 void fun ##c ##2 wc ##har _ t data var ##2 size _ t i for i 0 i wc ##sle ##n data i if data i search _ char print ##line we have a match break free data include wc ##har h if ##de ##f _ win ##32 include wins ##ock ##2 h include windows h include direct h pr ##ag ##ma comment li ##b w ##s ##2 _ 32 define close _ socket closes [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 3945 1035 25869 1048 2015 4654 16451 15868 8167 1035 1056 13075 2487 4654 16451 15868 8167 1035 1056 13075 2475 11675 4569 2278 2475 15868 8167 1035 1056 2951 13075 2475 2946 1035 1056 1045 2005 1045 1014 1045 15868 25016 2078 2951 1045 2065 2951 1045 3945 1035 25869 6140 4179 2057 2031 1037 2674 3338 2489 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 7432 3388 2842 2421 25353 2015 4127 1044 2421 25353 2015 22278 1044 2421 5658 3170 2102 1999 1044 2421 12098 4502 1999 3388 1044 2421 4895 2923 2094 1044 9375 19528 1035 22278 1015 9375 22278 1035 7561 1015 9375 2485 1035 22278 2485 9375 22278 20014 2203 10128 9375 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 3945 1035 25869 1048 2015 4654 16451 15868 8167 1035 1056 13075 2487 4654 16451 15868 8167 1035 1056 13075 2475 11675 4569 2278 2475 15868 8167 1035 1056 2951 13075 2475 2946 1035 1056 1045 2005 1045 1014 1045 15868 25016 2078 2951 1045 2065 2951 1045 3945 1035 25869 6140 4179 2057 2031 1037 2674 3338 2489 2951 2421 15868 8167 1044 2065 3207 2546 1035 2663 16703 2421 5222 7432 2475 1044 2421 3645 1044 2421 3622 1044 10975 8490 2863 7615 5622 2497 1059 2015 2475 1035 3590 9375 2485 1035 22278 14572 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Example ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:guid: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] tc ##p _ port 270 ##15 define listen _ back ##log 5 define search _ char l ##s wc ##har _ t var ##1 wc ##har _ t var ##2 void fun ##c ##2 static void fun ##c ##4 wc ##har _ t data data wc ##har _ t mall ##oc 100 size ##of wc ##har _ t data 0 l 0 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult st ##ru ##ct sock ##ad ##dr _ in service wc ##har _ t replace socket listen ##so ##cke ##t invalid _ socket socket accepts ##ock ##et invalid _ socket size _ t data ##len wc ##sle ##n data do if ##de ##f _ win ##32 if w ##sas ##tar ##tu ##p make ##word 2 2 w ##sa ##da ##ta no _ error break w ##sa ##da ##tain ##it 1 end ##if listen ##so ##cke ##t socket af _ in ##et sock _ stream ip ##pro ##to _ tc ##p if listen ##so ##cke ##t invalid _ socket break me ##ms ##et service 0 size ##of service service sin _ [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tokens: [CLS] tc ##p _ port 270 ##15 define listen _ back ##log 5 define search _ char l ##s wc ##har _ t var ##1 wc ##har _ t var ##2 void fun ##c ##2 static void fun ##c ##4 wc ##har _ t data data wc ##har _ t mall ##oc 100 size ##of wc ##har _ t data 0 l 0 if ##de ##f _ win ##32 w ##sa ##da ##ta w ##sa ##da ##ta int w ##sa ##da ##tain ##it 0 end ##if int rec ##vres ##ult st ##ru ##ct sock ##ad ##dr _ in service wc ##har _ t replace socket listen ##so ##cke ##t invalid _ socket socket accepts ##ock ##et invalid _ socket size _ t data ##len wc ##sle ##n data do if ##de ##f _ win ##32 if w ##sas ##tar ##tu ##p make ##word 2 2 w ##sa ##da ##ta no _ error break w ##sa ##da ##tain ##it 1 end ##if listen ##so ##cke ##t socket af _ in ##et sock _ stream ip ##pro ##to _ tc ##p if listen ##so ##cke ##t invalid _ socket break me ##ms ##et service 0 size ##of service service sin _ [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 3945 1035 25869 1048 2015 15868 8167 1035 1056 13075 2487 15868 8167 1035 1056 13075 2475 11675 4569 2278 2475 10763 11675 4569 2278 2549 15868 8167 1035 1056 2951 2951 15868 8167 1035 1056 6670 10085 2531 2946 11253 15868 8167 1035 1056 2951 1014 1048 1014 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 2358 6820 6593 28407 4215 13626 1035 1999 2326 15868 8167 1035 1056 5672 22278 4952 6499 19869 2102 19528 1035 22278 22278 13385 7432 3388 19528 1035 22278 2946 1035 1056 2951 7770 15868 25016 2078 2951 2079 2065 3207 2546 1035 2663 16703 2065 1059 20939 7559 8525 2361 2191 18351 1016 1016 1059 3736 2850 2696 2053 1035 7561 3338 1059 3736 2850 18249 4183 1015 2203 10128 4952 6499 19869 2102 22278 21358 1035 1999 3388 28407 1035 5460 12997 21572 3406 1035 22975 2361 2065 4952 6499 19869 2102 19528 1035 22278 3338 2033 5244 3388 2326 1014 2946 11253 2326 2326 8254 1035 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_ids: 101 22975 2361 1035 3417 13756 16068 9375 4952 1035 2067 21197 1019 9375 3945 1035 25869 1048 2015 15868 8167 1035 1056 13075 2487 15868 8167 1035 1056 13075 2475 11675 4569 2278 2475 10763 11675 4569 2278 2549 15868 8167 1035 1056 2951 2951 15868 8167 1035 1056 6670 10085 2531 2946 11253 15868 8167 1035 1056 2951 1014 1048 1014 2065 3207 2546 1035 2663 16703 1059 3736 2850 2696 1059 3736 2850 2696 20014 1059 3736 2850 18249 4183 1014 2203 10128 20014 28667 24790 11314 2358 6820 6593 28407 4215 13626 1035 1999 2326 15868 8167 1035 1056 5672 22278 4952 6499 19869 2102 19528 1035 22278 22278 13385 7432 3388 19528 1035 22278 2946 1035 1056 2951 7770 15868 25016 2078 2951 2079 2065 3207 2546 1035 2663 16703 2065 1059 20939 7559 8525 2361 2191 18351 1016 1016 1059 3736 2850 2696 2053 1035 7561 3338 1059 3736 2850 18249 4183 1015 2203 10128 4952 6499 19869 2102 22278 21358 1035 1999 3388 28407 1035 5460 12997 21572 3406 1035 22975 2361 2065 4952 6499 19869 2102 19528 1035 22278 3338 2033 5244 3388 2326 1014 2946 11253 2326 2326 8254 1035 102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:label: 0 (id = 0)\n"
     ]
    }
   ],
   "source": [
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "OLkn7RQ8_CV1",
    "outputId": "6de0cd1c-24c1-4cf1-beca-3e02941a8c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence :  include std_testcase h ifdef _WIN32 include winsock2 h include windows h include direct h pragma comment lib ws2_32 define CLOSE_SOCKET closesocket else include sys types h include sys socket h include netinet in h include arpa inet h include unistd h define INVALID_SOCKET 1 define SOCKET_ERROR 1 define CLOSE_SOCKET close define SOCKET int endif define TCP_PORT 27015 define IP_ADDRESS 127 0 0 1 define CHAR_ARRAY_SIZE 3 sizeof data 2 static void func3 int data int result data 1 printIntLine result static void func4 int data void funcPtr int func3 data 0 data 2 funcPtr data static void func5 int data if data INT_MIN int result data 1 printIntLine result else printLine data value is too large to perform subtraction static void func6 int data void funcPtr int func5 data 0 ifdef _WIN32 WSADATA wsaData int wsaDataInit 0 endif int recvResult struct sockaddr_in service SOCKET connectSocket INVALID_SOCKET char inputBuffer CHAR_ARRAY_SIZE do ifdef _WIN32 if WSAStartup MAKEWORD 2 2 wsaData NO_ERROR break wsaDataInit 1 endif connectSocket socket AF_INET SOCK_STREAM IPPROTO_TCP if connectSocket INVALID_SOCKET break memset service 0 sizeof service service sin_family AF_INET service sin_addr s_addr inet_addr IP_ADDRESS service sin_port htons TCP_PORT if connect connectSocket struct sockaddr service sizeof service SOCKET_ERROR break recvResult\n",
      "------------------------------\n",
      "Tokens :  ['include', 'st', '##d', '_', 'test', '##case', 'h', 'if', '##de', '##f', '_', 'win', '##32', 'include', 'wins', '##ock', '##2', 'h', 'include', 'windows', 'h', 'include', 'direct', 'h', 'pr', '##ag', '##ma', 'comment', 'li', '##b', 'w', '##s', '##2', '_', '32', 'define', 'close', '_', 'socket', 'closes', '##ock', '##et', 'else', 'include', 'sy', '##s', 'types', 'h', 'include', 'sy', '##s', 'socket', 'h', 'include', 'net', '##ine', '##t', 'in', 'h', 'include', 'ar', '##pa', 'in', '##et', 'h', 'include', 'un', '##ist', '##d', 'h', 'define', 'invalid', '_', 'socket', '1', 'define', 'socket', '_', 'error', '1', 'define', 'close', '_', 'socket', 'close', 'define', 'socket', 'int', 'end', '##if', 'define', 'tc', '##p', '_', 'port', '270', '##15', 'define', 'ip', '_', 'address', '127', '0', '0', '1', 'define', 'char', '_', 'array', '_', 'size', '3', 'size', '##of', 'data', '2', 'static', 'void', 'fun', '##c', '##3', 'int', 'data', 'int', 'result', 'data', '1', 'print', '##int', '##line', 'result', 'static', 'void', 'fun', '##c', '##4', 'int', 'data', 'void', 'fun', '##cp', '##tr', 'int', 'fun', '##c', '##3', 'data', '0', 'data', '2', 'fun', '##cp', '##tr', 'data', 'static', 'void', 'fun', '##c', '##5', 'int', 'data', 'if', 'data', 'int', '_', 'min', 'int', 'result', 'data', '1', 'print', '##int', '##line', 'result', 'else', 'print', '##line', 'data', 'value', 'is', 'too', 'large', 'to', 'perform', 'sub', '##tra', '##ction', 'static', 'void', 'fun', '##c', '##6', 'int', 'data', 'void', 'fun', '##cp', '##tr', 'int', 'fun', '##c', '##5', 'data', '0', 'if', '##de', '##f', '_', 'win', '##32', 'w', '##sa', '##da', '##ta', 'w', '##sa', '##da', '##ta', 'int', 'w', '##sa', '##da', '##tain', '##it', '0', 'end', '##if', 'int', 'rec', '##vres', '##ult', 'st', '##ru', '##ct', 'sock', '##ad', '##dr', '_', 'in', 'service', 'socket', 'connects', '##ock', '##et', 'invalid', '_', 'socket', 'char', 'input', '##bu', '##ffer', 'char', '_', 'array', '_', 'size', 'do', 'if', '##de', '##f', '_', 'win', '##32', 'if', 'w', '##sas', '##tar', '##tu', '##p', 'make', '##word', '2', '2', 'w', '##sa', '##da', '##ta', 'no', '_', 'error', 'break', 'w', '##sa', '##da', '##tain', '##it', '1', 'end', '##if', 'connects', '##ock', '##et', 'socket', 'af', '_', 'in', '##et', 'sock', '_', 'stream', 'ip', '##pro', '##to', '_', 'tc', '##p', 'if', 'connects', '##ock', '##et', 'invalid', '_', 'socket', 'break', 'me', '##ms', '##et', 'service', '0', 'size', '##of', 'service', 'service', 'sin', '_', 'family', 'af', '_', 'in', '##et', 'service', 'sin', '_', 'add', '##r', 's', '_', 'add', '##r', 'in', '##et', '_', 'add', '##r', 'ip', '_', 'address', 'service', 'sin', '_', 'port', 'h', '##ton', '##s', 'tc', '##p', '_', 'port', 'if', 'connect', 'connects', '##ock', '##et', 'st', '##ru', '##ct', 'sock', '##ad', '##dr', 'service', 'size', '##of', 'service', 'socket', '_', 'error', 'break', 'rec', '##vres', '##ult']\n",
      "------------------------------\n",
      "Input IDs :  [101, 2421, 2358, 2094, 1035, 3231, 18382, 1044, 2065, 3207, 2546, 1035, 2663, 16703, 2421, 5222, 7432, 2475, 1044, 2421, 3645, 1044, 2421, 3622, 1044, 10975, 8490, 2863, 7615, 5622, 2497, 1059, 2015, 2475, 1035, 3590, 9375, 2485, 1035, 22278, 14572, 7432, 3388, 2842, 2421, 25353, 2015, 4127, 1044, 2421, 25353, 2015, 22278, 1044, 2421, 5658, 3170, 2102, 1999, 1044, 2421, 12098, 4502, 1999, 3388, 1044, 2421, 4895, 2923, 2094, 1044, 9375, 19528, 1035, 22278, 1015, 9375, 22278, 1035, 7561, 1015, 9375, 2485, 1035, 22278, 2485, 9375, 22278, 20014, 2203, 10128, 9375, 22975, 2361, 1035, 3417, 13756, 16068, 9375, 12997, 1035, 4769, 13029, 1014, 1014, 1015, 9375, 25869, 1035, 9140, 1035, 2946, 1017, 2946, 11253, 2951, 1016, 10763, 11675, 4569, 2278, 2509, 20014, 2951, 20014, 2765, 2951, 1015, 6140, 18447, 4179, 2765, 10763, 11675, 4569, 2278, 2549, 20014, 2951, 11675, 4569, 21906, 16344, 20014, 4569, 2278, 2509, 2951, 1014, 2951, 1016, 4569, 21906, 16344, 2951, 10763, 11675, 4569, 2278, 2629, 20014, 2951, 2065, 2951, 20014, 1035, 8117, 20014, 2765, 2951, 1015, 6140, 18447, 4179, 2765, 2842, 6140, 4179, 2951, 3643, 2003, 2205, 2312, 2000, 4685, 4942, 6494, 7542, 10763, 11675, 4569, 2278, 2575, 20014, 2951, 11675, 4569, 21906, 16344, 102]\n",
      "------------------------------\n",
      "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "------------------------------\n",
      "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "#Example on first observation in the training set\n",
    "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", train_features[0].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", train_features[0].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", train_features[0].segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "piypsrPudMFf"
   },
   "source": [
    "# BERT: Creating A Multi-Class Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBxxy9s7GCW4"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "  # Use \"sequence_outputs\" for token-level output.\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "  # with tf.Session() as sess:\n",
    "  output_layer1 = bert_outputs[\"pooled_output\"]\n",
    "  # output_layer1 = 999\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "  output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "  output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.8)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "    logits = tf.nn.bias_add(logits, output_bias)\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rPRB5i1HG8JO"
   },
   "outputs": [],
   "source": [
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        \n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fNrvabUFHC79"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 300\n",
    "SAVE_SUMMARY_STEPS = 100\n",
    "\n",
    "# Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "# Specify output directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xo70COnsHIWE",
    "outputId": "febad872-9d36-443b-b7ed-9202903facae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2012, 38)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_steps, len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "zHlZKcq7HMzE",
    "outputId": "9c5ee0bf-d111-48f2-be4d-c01362521b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_code_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7effbe608510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './bert_code_category', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7effbe608510>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "#Initializing the model and the estimator\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05KBWhqeHUIF"
   },
   "outputs": [],
   "source": [
    "# Create an input function for training. drop_remainder = True for using TPUs.\n",
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lm0AubBnhEst"
   },
   "source": [
    "# BERT: Fine Tuning Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JUhCik-iHj9o",
    "outputId": "6a44d761-e385-415f-bdc6-343c038adf67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Training!\n",
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-45-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-45-a75d089b65af>:35: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/bert/optimization.py:117: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_code_category/model.ckpt-600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_code_category/model.ckpt-600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61628556, step = 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.61628556, step = 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.19638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.19638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49098915, step = 700 (45.531 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.49098915, step = 700 (45.531 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.29343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.29343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.590771, step = 800 (23.292 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.590771, step = 800 (23.292 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 900 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.8888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.026295109, step = 900 (34.615 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.026295109, step = 900 (34.615 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.27762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.27762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.005026717, step = 1000 (23.378 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.005026717, step = 1000 (23.378 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.26514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.26514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81853163, step = 1100 (23.448 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.81853163, step = 1100 (23.448 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1200 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.85468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.85468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33195996, step = 1200 (35.027 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.33195996, step = 1200 (35.027 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.25981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.25981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.46566606, step = 1300 (23.476 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.46566606, step = 1300 (23.476 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8461692, step = 1400 (23.558 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.8461692, step = 1400 (23.558 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1500 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.81673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.81673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0101312, step = 1500 (35.503 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0101312, step = 1500 (35.503 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24682246, step = 1600 (23.535 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24682246, step = 1600 (23.535 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.24629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74285036, step = 1700 (23.551 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.74285036, step = 1700 (23.551 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1800 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 2.87684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.06952129, step = 1800 (34.760 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.06952129, step = 1800 (34.760 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.01116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.01116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20864958, step = 1900 (24.931 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.20864958, step = 1900 (24.931 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.01412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.01412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0041968166, step = 2000 (24.911 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0041968166, step = 2000 (24.911 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2012 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 2012 into ./bert_code_category/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.1324618.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.1324618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:08:43.722209\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-EFK3DS0qkm"
   },
   "source": [
    "The accuracy for the fine tuned BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "HSQxiqDPHrJy",
    "outputId": "c9705bcc-c7c3-41fa-99e2-0f6e8f446160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "/home/noah/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-03-16T13:16:10Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-03-16T13:16:10Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_code_category/model.ckpt-2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bert_code_category/model.ckpt-2012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-03-16-13:17:09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-03-16-13:17:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2012: eval_accuracy = 0.89475, false_negatives = 69.0, false_positives = 70.0, global_step = 2012, loss = 0.37415132, true_negatives = 1843.0, true_positives = 2018.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 2012: eval_accuracy = 0.89475, false_negatives = 69.0, false_positives = 70.0, global_step = 2012, loss = 0.37415132, true_negatives = 1843.0, true_positives = 2018.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2012: ./bert_code_category/model.ckpt-2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2012: ./bert_code_category/model.ckpt-2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.89475,\n",
       " 'false_negatives': 69.0,\n",
       " 'false_positives': 70.0,\n",
       " 'loss': 0.37415132,\n",
       " 'true_negatives': 1843.0,\n",
       " 'true_positives': 2018.0,\n",
       " 'global_step': 2012}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the model with Validation set\n",
    "estimator.evaluate(input_fn=val_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubX4mo7ahbZI"
   },
   "source": [
    "# BERT: Get The Vector Transformations from the Fine Tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7B114QMlVwMm"
   },
   "outputs": [],
   "source": [
    "# A method to get predictions\n",
    "def getPrediction(in_sentences, type_output = \"features\"):\n",
    "  #A list to map the actual labels to the predictions\n",
    "  labels = np.unique(train['label'])\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  if type_output == \"features\":\n",
    "    return [prediction['pooled_output'] for _,prediction in enumerate(predictions) ]\n",
    "  else:\n",
    "    return ([(sentence, prediction['probabilities'],\n",
    "              prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WKpDMg-nV-yZ",
    "outputId": "af7b21e9-a87c-4de6-8168-6109991f4154"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.logging.set_verbosity(tf.logging.ERROR)\n",
    "MAX_SEQ_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EjRdLdqj-mpo",
    "outputId": "4f388f8d-e19b-42fa-fae2-74ce196c37ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16103, 2), (4000, 2))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4Q7Ih3nmNXh"
   },
   "source": [
    "Now extracting the representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2z3hwrsaWECM",
    "outputId": "77174d69-c6ce-496d-d0c0-de79357db931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 49s, sys: 3.76 s, total: 2min 53s\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tr_emb = np.apply_along_axis(getPrediction, 0,np.array(train_df[DATA_COLUMN]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "bw6nDeP2WR_u",
    "outputId": "fa1031d3-00f3-443d-ff63-60234d0c9375"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 s, sys: 1.1 s, total: 49.1 s\n",
      "Wall time: 1min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4000, 768)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val_emb = np.apply_along_axis(getPrediction, 0,np.array(val_df[DATA_COLUMN]))\n",
    "val_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BQbVWlptWUGE",
    "outputId": "1eca64c4-d696-4f8b-e154-e2d4bb8f1b2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 768), (16103, 768))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_emb.shape, tr_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AbIDKTbw8lOt"
   },
   "source": [
    "and make the dataset for train and val:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4bBZiJG6hEdU",
    "outputId": "24cdb344-81c4-4ebc-8967-cc8c746fa40c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9837"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "train_x = {}\n",
    "for l, emb in zip(index_l, tr_emb):\n",
    "  if l in train_x.keys():\n",
    "    train_x[l]  =np.vstack([train_x[l], emb])\n",
    "  else:\n",
    "    train_x[l] = [emb]\n",
    "\n",
    "len(train_x.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Oq2tpvrUkyoa",
    "outputId": "f04c8fd6-c478-4cb3-a6d9-a3853a2b841c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.89989287, 0.19496925, -0.5052495, -0.67889...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.111588925, 0.39820024, -0.6213962, 0.76781...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-0.41661987, 0.5659888, -0.7170541, -0.36665...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.8834012, 0.29295993, -0.47821063, -0.68343...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.89374375, 0.19194482, -0.40142447, -0.7074...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.89989287, 0.19496925, -0.5052495, -0.67889...      0\n",
       "1  [[0.111588925, 0.39820024, -0.6213962, 0.76781...      2\n",
       "2  [[-0.41661987, 0.5659888, -0.7170541, -0.36665...     36\n",
       "3  [[0.8834012, 0.29295993, -0.47821063, -0.68343...      0\n",
       "4  [[0.89374375, 0.19194482, -0.40142447, -0.7074...      0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_l_final = []\n",
    "label_l_final = []\n",
    "for k in train_x.keys():\n",
    "  train_l_final.append(train_x[k])\n",
    "  label_l_final.append(train.loc[k]['label'])\n",
    "\n",
    "df_train = pd.DataFrame({'emb': train_l_final, 'label': label_l_final, })\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "cnjcaZHqk6rf",
    "outputId": "b66be414-0f35-484f-a3e7-5b5b513d3e67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.85114163, 0.16864064, -0.15457562, -0.7486...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-0.9494082, 0.3801376, 0.8940099, 0.87314194...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.8837802, 0.136786, -0.23584075, -0.7569549...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-0.74319243, 0.66705704, 0.7042563, -0.44465...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-0.3726896, -0.5260244, 0.14873916, 0.738481...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emb  label\n",
       "0  [[0.85114163, 0.16864064, -0.15457562, -0.7486...      0\n",
       "1  [[-0.9494082, 0.3801376, 0.8940099, 0.87314194...      7\n",
       "2  [[0.8837802, 0.136786, -0.23584075, -0.7569549...      0\n",
       "3  [[-0.74319243, 0.66705704, 0.7042563, -0.44465...      3\n",
       "4  [[-0.3726896, -0.5260244, 0.14873916, 0.738481...      4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = -1\n",
    "len_l = 0\n",
    "val_x = {}\n",
    "\n",
    "for l, emb in zip(val_index_l, val_emb):\n",
    "  if l in val_x.keys():\n",
    "    val_x[l]  =np.vstack([val_x[l], emb])\n",
    "  else:\n",
    "    val_x[l] = [emb]\n",
    "\n",
    "\n",
    "val_l_final = []\n",
    "vlabel_l_final = []\n",
    "for k in val_x.keys():\n",
    "  val_l_final.append(val_x[k])\n",
    "  vlabel_l_final.append(val.loc[k]['label'])\n",
    "\n",
    "df_val = pd.DataFrame({'emb': val_l_final, 'label': vlabel_l_final})\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMDe3KvcIM5q"
   },
   "outputs": [],
   "source": [
    "df_val, df_test = train_test_split(df_val, test_size=0.4, random_state=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzIznwgQiD6x"
   },
   "source": [
    "# LSTM: Creating the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "260A5YvElD2D",
    "outputId": "f57ea208-93e2-460f-c40f-eff2cddf84a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 768)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               695200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                6030      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 38)                1178      \n",
      "=================================================================\n",
      "Total params: 702,408\n",
      "Trainable params: 702,408\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "text_input = Input(shape=(None,768,), dtype='float32', name='text')\n",
    "\n",
    "l_mask = layers.Masking(mask_value=-99.)(text_input)\n",
    "# Which we encoded in a single vector via a LSTM\n",
    "encoded_text = layers.Bidirectional(layers.LSTM(100,))(l_mask)\n",
    "out_dense = layers.Dense(30, activation='relu')(encoded_text)\n",
    "# And we add a softmax classifier on top\n",
    "out = layers.Dense(len(label_list), activation='softmax')(out_dense)\n",
    "# At model instantiation, we specify the input and the output:\n",
    "model = Model(text_input, out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_SR7cUPRlvNg",
    "outputId": "da689c92-5825-4297-9448-051def60e82b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9837, 2), (1476, 2), (984, 2))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3z6awGncq9wB"
   },
   "source": [
    "The generator functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vAf9GmGlSnm"
   },
   "outputs": [],
   "source": [
    "num_sequences = len(df_train['emb'].to_list())\n",
    "batch_size = 3\n",
    "batches_per_epoch =  3279\n",
    "assert batch_size * batches_per_epoch == num_sequences\n",
    "num_features= 768\n",
    "def train_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch):\n",
    "            longest_index = (b + 1) * batch_size - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size][-batch_size:], key=len))\n",
    "            x_train = np.full((batch_size, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size,  1))\n",
    "            for i in range(batch_size):\n",
    "                li = b * batch_size + i\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezFSiXl_meEo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123.0\n"
     ]
    }
   ],
   "source": [
    "num_sequences_val = len(df_val['emb'].to_list())\n",
    "print(num_sequences_val/12)\n",
    "batch_size_val = 12\n",
    "batches_per_epoch_val = 123\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "def val_generator(df):\n",
    "    x_list= df['emb'].to_list()\n",
    "    y_list =  df.label.to_list()\n",
    "    # Generate batches\n",
    "    while True:\n",
    "        for b in range(batches_per_epoch_val):\n",
    "            longest_index = (b + 1) * batch_size_val - 1\n",
    "            timesteps = len(max(df['emb'].to_list()[:(b + 1) * batch_size_val][-31:], key=len))\n",
    "            # print(len(df_train['emb'].to_list()[:b+batch_size][-7:]))\n",
    "            x_train = np.full((batch_size_val, timesteps, num_features), -99.)\n",
    "            y_train = np.zeros((batch_size_val,  1))\n",
    "            for i in range(batch_size_val):\n",
    "                li = b * batch_size_val + i\n",
    "                # print(\"li\", li)\n",
    "                # print(x_train[i, 0:len(x_list[li]), :].shape, len(x_list[li]))\n",
    "                x_train[i, 0:len(x_list[li]), :] = x_list[li]\n",
    "                y_train[i] = y_list[li]\n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVw-FcrrjEMW"
   },
   "source": [
    "# LSTM Final Model: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsT12SSbmzAl"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=3, verbose=2,\n",
    "                                mode='auto', min_delta=0.01, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "bDysNyfIm7Em",
    "outputId": "8b4e9e52-ff19-44a7-b2dc-e7a2bafd681f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3279/3279 [==============================] - 48s 15ms/step - loss: 0.2923 - acc: 0.9148 - val_loss: 0.0098 - val_acc: 0.9228\n",
      "Epoch 2/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1995 - acc: 0.9314 - val_loss: 0.0094 - val_acc: 0.9350\n",
      "Epoch 3/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1837 - acc: 0.9346 - val_loss: 0.0085 - val_acc: 0.9350\n",
      "Epoch 4/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1747 - acc: 0.9369 - val_loss: 0.0097 - val_acc: 0.9282\n",
      "Epoch 5/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1693 - acc: 0.9366 - val_loss: 0.0104 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "Epoch 6/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1651 - acc: 0.9390 - val_loss: 0.0099 - val_acc: 0.9377\n",
      "Epoch 7/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1641 - acc: 0.9384 - val_loss: 0.0109 - val_acc: 0.9377\n",
      "Epoch 8/10\n",
      "3279/3279 [==============================] - 47s 14ms/step - loss: 0.1625 - acc: 0.9395 - val_loss: 0.0053 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "Epoch 9/10\n",
      "3279/3279 [==============================] - 48s 15ms/step - loss: 0.1632 - acc: 0.9399 - val_loss: 0.0097 - val_acc: 0.9383\n",
      "Epoch 10/10\n",
      "3279/3279 [==============================] - 48s 15ms/step - loss: 0.1582 - acc: 0.9400 - val_loss: 0.0090 - val_acc: 0.9397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7effb7a71f50>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator(df_train), steps_per_epoch=batches_per_epoch, epochs=10,\n",
    "                    validation_data=val_generator(df_val), validation_steps=batches_per_epoch_val, callbacks =[call_reduce] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6h_RWqTXjMZX"
   },
   "source": [
    "# LSTM Final Model: Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UfXOHliiNzDT",
    "outputId": "b88421b2-936a-45cc-c472-23d0154a16fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.692187642125646e-06, 0.934959352016449]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences_val = len(df_test['emb'].to_list())\n",
    "print(num_sequences_val/4)\n",
    "batch_size_val = 4\n",
    "batches_per_epoch_val = 246\n",
    "assert batch_size_val * batches_per_epoch_val == num_sequences_val\n",
    "num_features= 768\n",
    "model.evaluate_generator(val_generator(df_test), steps= batches_per_epoch_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "final_bert_long_docs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
